<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhihao Zhang</title>

  <meta name="author" content="Zhihao Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Zhihao Zhang (Âº†ÂøóÊµ©)</name>
                  </p>
                  <p> I am a first-year CS Ph.D. student focusing on 3D computer vision at <a
                      href="https://engineering.msu.edu/about/departments/cse">Michigan State University</a> (MSU),
                    where my advisor is Prof. <a href="https://www.cse.msu.edu/~liuxm/index2.html">Xiaoming Liu</a>.
                    Before that, I graduated from <a href="http://en.xjtu.edu.cn/">Xi‚Äôan Jiaotong University</a>
                    (XJTU) with a Bachelor & Master degree in Computer Science, advised by <a
                      href="https://gr.xjtu.edu.cn/web/zhangwzh123">Weizhan Zhang</a>.
                  </p>
                  <p>
                    Prior to joining MSU, I interned at <a
                      href="https://www.tri.global/our-work/machine-learning">University of Illinois
                      Urabana-Champaign</a> (UIUC) with Prof. <a href="https://yxw.web.illinois.edu/">Yu-Xiong Wang</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zhan2365@msu.edu">Email</a> &nbsp/&nbsp
                    <a href="./files/cv_formal.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=4bCjIH0AAAAJ\&hl=zh-CN">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://x.com/ZhihaoZ75030773">Twitter (X)</a> &nbsp/&nbsp
                    <a href="https://github.com/alanzhangcs">Github</a> &nbsp/&nbsp
                    <!-- <a href="https://www.zhihu.com/people/pang-zi-qi-40">Áü•‰πé</a> -->
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/zhihaozhang.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/zhihaozhang.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My research interests lie at the intersection of <strong>multi-modal learning</strong> and
                    <strong>computer vision</strong> with the long-term goal of empowering computational models to
                    better perceive and interact
                    with the 3D visual world.
                    Currently, I'm working on:
                  <ul>
                    <li>3D shape understanding, 3D object detection for autonomous driving </li>
                    <li>Multi-modal learning for 3D perception</li>
                  </ul>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="rmem_stop()" onmouseover="rmem_start()">
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="two" id='tamm_image'><img src="images/tamm.png"
                      style="width:100%;height:auto;float:left;margin:right 20px;"></div>
                </td>
                <td style="padding:30px;width:75%;vertical-align:middle">
                  <papertitle>TAMM: TriAdapter Multi-Modal Learning for 3D Shape Understanding
                  </papertitle>
                  <br>
                  <strong>Zhihao Zhang</strong>*,
                  <a href="https://shengcao-cao.github.io/">Shengcao Cao*</a>
                  <a href="https://yxw.web.illinois.edu/">Yu-Xiong Wang</a>
                  <br>
                  <em> CVPR </em>, 2024
                  <br>
                  <a href="https://alanzhangcs.github.io/tamm-page/">Project Page</a>
                  /
                  <a href="https://github.com/alanzhangcs/Tamm_Code">Code</a>
                  /
                  <a href="https://arxiv.org/pdf/2402.18490">arXiv</a>
                  <p>
                    Introduce TriAdapter Multi-Modal Learning (TAMM), a novel
                    two-stage learning approach based on three synergistic
                    adapters to different modalities in the pre-training.
                  </p>
                </td>
              </tr>


              <tr onmouseout="mftr_stop()" onmouseover="mftr_start()">
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="two" id='lidarsot_image'><img src="images/mftr.png" style="width:100%;height:auto">
                  </div>
                </td>
                <td style="padding:30px;width:75%;vertical-align:middle">
                  <papertitle>Tile Classification Based Viewport Prediction with Multi-modal Fusion Transformer
                  </papertitle>
                  <br>
                  <strong>Zhihao Zhang</strong>*,
                  <a href="https://scholar.google.com/citations?user=wmYVogQAAAAJ&hl=en">Yiwei Chen</a>*,
                  <a href="https://gr.xjtu.edu.cn/web/zhangwzh123">Weizhan Zhang</a>,
                  Caixia Yan, Qinghua Zheng, Qi Wang, Wangdu Chen
                  <br>
                  <em> ACM MM </em>, 2023
                  <br>
                  <a href="https://github.com/alanzhangcs/MFTR">Code</a>
                  /
                  <a href="https://arxiv.org/pdf/2309.14704">arXiv</a>
                  <p></p>
                  <p>
                    Propose a tile classification based viewport prediction method with Multi-modal Fusion Transformer
                    to improve the robustness of viewport prediction.
                  </p>
                </td>
              </tr>


            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding:40px">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Huge thanks to Jon Barron for proving the template for the page.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>